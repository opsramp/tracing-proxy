# use replicaCount to specify the size of the trace-proxy cluster
replicaCount: 3

# configure the cpu and memory limits for each node in the cluster
#resources:
#  limits:
#    cpu: "2000m"
#    memory: "4Gi"
#  requests:
#    cpu: "500m"
#    memory: "1Gi"


image:
  repository: us-docker.pkg.dev/opsramp-registry/agent-images/trace-proxy
  pullPolicy: Always # use "IfNotPresent" to avoid pulling the image every time
  tag: "latest" # if empty, then defaults to the chart appVersion.


podAnnotations: { }
imagePullSecrets: [ ]
nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  http: 8082
  peer: 8081
  grpc: 9090
  grpcPeer: 8084
  annotations: { }

config:
  # ListenAddr is the IP and port on which to listen for incoming events.
  ListenAddr: 0.0.0.0:{{include "httpPort" . | trim }}

  # GRPCListenAddr is the IP and port on which to listen for incoming events over gRPC.
  GRPCListenAddr: 0.0.0.0:{{include "grpcPort" . | trim }}

  # PeerListenAddr is the IP and port on which to listen for traffic being rerouted from a peer.
  PeerListenAddr: 0.0.0.0:{{include "httpPeerPort" . | trim }}

  GRPCPeerListenAddr: 0.0.0.0:{{include "grpcPeerPort" . | trim }}

  # ProxyProtocol accepts http and https
  # Not Eligible for live reload.
  ProxyProtocol: ""
  # ProxyServer takes the proxy server address
  # Not Eligible for live reload.
  ProxyServer: ""
  # ProxyPort takes the proxy server port
  # Not Eligible for live reload.
  ProxyPort: 3128
  # ProxyUserName takes the proxy username
  # Not Eligible for live reload.
  ProxyUserName: ""
  # ProxyPassword takes the proxy password
  # Not Eligible for live reload.
  ProxyPassword: ""

  # CompressPeerCommunication determines whether trace-proxy will compress span data
  # it forwards to peers. If it costs money to transmit data between refinery
  # instances (e.g. they're spread across AWS availability zones), then you
  # almost certainly want compression enabled to reduce your bill. The option to
  # disable it is provided as an escape hatch for deployments that value lower CPU
  # utilization over data transfer costs.
  CompressPeerCommunication: true

  # APIKeys is a list of OpsRamp API keys that the proxy will accept. This list
  # only applies to events - other OpsRamp API actions will fall through to the
  # upstream API directly.
  # Adding keys here causes events arriving with API keys not in this list to be
  # rejected with an HTTP 401 error If an API key that is a literal '*' is in the
  # list, all API keys are accepted.
  # Eligible for live reload.
  APIKeys: [ "*" ]# wildcard accepts all keys

  # OpsrampAPI is the URL for the upstream Opsramp API.
  # Eligible for live reload.
  OpsrampAPI: ""
  # OpsrampKey is used to get the OauthToken
  OpsrampKey: ""
  # OpsrampSecret is used to get the OauthToken
  OpsrampSecret: ""
  # Traces are sent to the client with the given tenantId
  TenantId: ""
  # Dataset you want to use for sampling
  Dataset: "ds"
  #Tls Options
  UseTls: true
  UseTlsInsecure: false

  # LoggingLevel valid options are "debug", "info", "error", and "panic".
  LoggingLevel: error

  # SendDelay is a short timer that will be triggered when a trace is complete.
  # Trace Proxy will wait for this duration before actually sending the trace.  The
  # reason for this short delay is to allow for small network delays or clock
  # jitters to elapse and any final spans to arrive before actually sending the
  # trace.  This supports duration strings with supplied units. Set to 0 for
  # immediate sends.
  SendDelay: 2s

  # BatchTimeout dictates how frequently to send unfulfilled batches. By default
  # this will use the DefaultBatchTimeout in libtrace as its value, which is 100ms.
  # Eligible for live reload.
  BatchTimeout: 1s

  # TraceTimeout is a long timer; it represents the outside boundary of how long
  # to wait before sending an incomplete trace. Normally traces are sent when the
  # root span arrives. Sometimes the root span never arrives (due to crashes or
  # whatever), and this timer will send a trace even without having received the
  # root span. If you have particularly long-lived traces you should increase this
  # timer. This supports duration strings with supplied units.
  TraceTimeout: 60s

  # MaxBatchSize is the number of events to be included in the batch for sending
  MaxBatchSize: 500

  # SendTicker is a short timer; it determines the duration to use to check for traces to send
  SendTicker: 100ms

  # UpstreamBufferSize and PeerBufferSize control how large of an event queue to use
  # when buffering events that will be forwarded to peers or the upstream API.
  UpstreamBufferSize: 1000
  PeerBufferSize: 1000

  # EnvironmentCacheTTL is the amount of time a cache entry will live that associates
  # an API key with an environment name.
  # Cache misses lookup the environment name using HoneycombAPI config value.
  # Default is 1 hour ("1h").
  # Not eligible for live reload.
  EnvironmentCacheTTL: "1h"

  # QueryAuthToken, if specified, provides a token that must be specified with
  # the header "X-Honeycomb-Refinery-Query" in order for a /query request to succeed.
  # These /query requests are intended for debugging refinery installations and
  # are not typically needed in normal operation.
  # Can be specified in the environment as REFINERY_QUERY_AUTH_TOKEN.
  # If left unspecified, the /query endpoints are inaccessible.
  # Not eligible for live reload.
  # QueryAuthToken: "some-random-value"

  # AddRuleReasonToTrace causes traces that are sent to Honeycomb to include the field `meta.refinery.reason`.
  # This field contains text indicating which rule was evaluated that caused the trace to be included.
  # Eligible for live reload.
  AddRuleReasonToTrace: true

  # AdditionalErrorFields should be a list of span fields that should be included when logging
  # errors that happen during ingestion of events (for example, the span too large error).
  # This is primarily useful in trying to track down misbehaving senders in a large installation.
  # The fields `dataset`, `apihost`, and `environment` are always included.
  # If a field is not present in the span, it will not be present in the error log.
  # Default is ["trace.span_id"].
  # Eligible for live reload.
  AdditionalErrorFields:
    - trace.span_id

  # AddSpanCountToRoot adds a new metadata field, `meta.span_count` to root spans to indicate
  # the number of child spans on the trace at the time the sampling decision was made.
  # This value is available to the rules-based sampler, making it possible to write rules that
  # are dependent upon the number of spans in the trace.
  # Default is false.
  # Eligible for live reload.
  AddSpanCountToRoot: false

  # CacheOverrunStrategy controls the cache management behavior under memory pressure.
  # "resize" means that when a cache overrun occurs, the cache is shrunk and never grows again,
  # which is generally not helpful unless it occurs because of a permanent change in traffic patterns.
  # In the "impact" strategy, the items having the most impact on the cache size are
  # ejected from the cache earlier than normal but the cache is not resized.
  # In all cases, it only applies if MaxAlloc is nonzero.
  # Default is "resize" for compatibility but "impact" is recommended for most installations.
  # Eligible for live reload.
  CacheOverrunStrategy: "impact"

  # Metrics are sent to OpsRamp (The collection happens based on configuration specifie
  # in OpsRampMetrics and only works when the Metrics is set to "prometheus")
  SendMetricsToOpsRamp: false

  # Configure how Refinery peers are discovered and managed
  PeerManagement:
    Strategy: "hash" # Always use hash for balanced distribution of traces

    # The type should always be redis when deployed to Kubernetes environments
    Type: "redis"

    # RedisHost is used to connect to redis for peer cluster membership management.
    # Further, if the environment variable 'REFINERY_REDIS_HOST' is set it takes
    # precedence and this value is ignored.
    # Not eligible for live reload.
    # RedisHost will default to the name used for the release or name overrides depending on what is used,
    # but can be overriden to a specific value.
    RedisHost: '{{include "opsramp-tracing-proxy.redis.fullname" .}}:6379'

    # RedisUsername is the username used to connect to redis for peer cluster membership management.
    # If the environment variable 'REFINERY_REDIS_USERNAME' is set it takes
    # precedence and this value is ignored.
    # Not eligible for live reload.
    RedisUsername: ""

    # RedisPassword is the password used to connect to redis for peer cluster membership management.
    # If the environment variable 'REFINERY_REDIS_PASSWORD' is set it takes
    # precedence and this value is ignored.
    # Not eligible for live reload.
    RedisPassword: ""

    # UseTLS enables TLS when connecting to redis for peer cluster membership management, and sets the MinVersion to 1.2.
    # Not eligible for live reload.
    UseTLS: false

    # UseTLSInsecure disables certificate checks
    # Not eligible for live reload.
    UseTLSInsecure: false

    # IdentifierInterfaceName is optional.
    # Due to the nature of DNS in Kubernetes, it is recommended to set this value to the 'eth0' interface name.
    # When configured the pod's IP will be used in the peer list
    IdentifierInterfaceName: eth0

    # UseIPV6Identifier is optional. If using IdentifierInterfaceName, Trace Proxy will default to the first
    # IPv4 unicast address it finds for the specified interface. If UseIPV6Identifier is used, will use
    # the first IPV6 unicast address found.
    UseIPV6Identifier: false

  ############################
  ## Implementation Choices ##
  ############################
  # Each of the config options below chooses an implementation of a Refinery
  # component to use. Depending on the choice there may be more configuration
  # required below in the section for that choice. Changing implementation choices
  # requires a process restart; these changes will not be picked up by a live
  # config reload. (Individual config options for a given implementation may be
  # eligible for live reload).
  # Collector describes which collector to use for collecting traces. The only
  # current valid option is "InMemCollector".. More can be added by adding
  # implementations of the Collector interface.
  Collector: "InMemCollector"

  # InMemCollector brings together all the settings that are relevant to
  # collecting spans together to make traces.
  InMemCollector:

    # The collection cache is used to collect all spans into a trace as well as
    # remember the sampling decision for any spans that might come in after the
    # trace has been marked "complete" (either by timing out or seeing the root
    # span). The number of traces in the cache should be many multiples (100x to
    # 1000x) of the total number of concurrently active traces (trace throughput *
    # trace duration).
    CacheCapacity: 1000

    # MaxAlloc is optional. If set, it must be an integer >= 0.
    # If set to a non-zero value, once per tick (see SendTicker) the collector
    # will compare total allocated bytes to this value. If allocation is too
    # high, cache capacity will be reduced and an error will be logged.
    # Useful values for this setting are generally in the range of 75%-90% of
    # available system memory. Using 80% is the recommended.
    # This value should be set in according to the resources.limits.memory
    # By default that setting is 4GB, and this is set to 85% of that limit
    # 4 * 1024 * 1024 * 1024 * 0.80 = 3,435,973,837
    # MaxAlloc: 3435973836
    MaxAlloc: 0

  # LogrusLogger is a section of the config only used if you are using the
  # LogrusLogger to send all logs to STDOUT using the logrus package.
  LogrusLogger:
    # LogFormatter specifies the log format. Accepted values are one of ["logfmt", "json"]
    LogFormatter: 'json'
    # LogOutput specifies where the logs are supposed to be written. Accpets one of ["stdout", "stderr"]
    LogOutput: 'stdout'

  OpsRampMetrics:
    # MetricsListenAddr determines the interface and port on which Prometheus will
    # listen for requests for /metrics. Must be different from the main Refinery
    # listener.
    # Not eligible for live reload.
    MetricsListenAddr: 'localhost:2112'

    # OpsRampMetricsAPI is the URL for the upstream OpsRamp API.
    # Not Eligible for live reload.
    OpsRampMetricsAPI: ''

    # OpsRampTenantID is the Client or Tenant ID where the metrics are supposed to be pushed.
    OpsRampTenantID: ''

    # OpsRampMetricsAPIKey is the API key to use to send metrics to the OpsRamp.
    # This is separate from the APIKeys used to authenticate regular
    # traffic.
    # Not Eligible for live reload.
    OpsRampMetricsAPIKey: ''

    # OpsRampMetricsAPISecret is the API Secret to use to send metrics to the OpsRamp.
    # This is separate from the APISecret used to authenticate regular
    # traffic.
    # Not Eligible for live reload.
    OpsRampMetricsAPISecret: ''

    # OpsRampMetricsReportingInterval is frequency specified in seconds at which
    # the metrics are collected and sent to OpsRamp
    # Not Eligible for live reload.
    OpsRampMetricsReportingInterval: 10

    # OpsRampMetricsRetryCount is the number of times we retry incase the send fails
    # Not Eligible for live reload.
    OpsRampMetricsRetryCount: 2

    # ProxyProtocol accepts http and https
    # Not Eligible for live reload.
    ProxyProtocol: ''

    # ProxyServer takes the proxy server address
    # Not Eligible for live reload.
    ProxyServer: ''

    # ProxyPort takes the proxy server port
    # Not Eligible for live reload.
    ProxyPort: 3128

    # ProxyUserName takes the proxy username
    # Not Eligible for live reload.
    ProxyUserName: ''

    # ProxyPassword takes the proxy password
    # Not Eligible for live reload.
    ProxyPassword: ''

    # OpsRampMetricsList is a list of regular expressions which match the metric
    # names. Keep the list as small as possible since too many regular expressions can lead to bad performance.
    # Internally all the regex in the list are concatinated using '|' to make the computation little faster.
    # Not Eligible for live reload
    OpsRampMetricsList: [ ".*" ]


rules:
  # DryRun - If enabled, marks traces that would be dropped given current sampling rules,
  # and sends all traces regardless
  DryRun: true
  # lb:
  # This is the default sampler used.
  # Any traces received that are not for a defined dataset will use this sampler.
  # Deterministic Sampler implementation. This is the simplest sampling algorithm
  # - it is a static sample rate, choosing traces randomly to either keep or send
  # (at the appropriate rate). It is not influenced by the contents of the trace.
  Sampler: DeterministicSampler

  # SampleRate is the rate at which to sample. It indicates a ratio, where one
  # sample trace is kept for every n traces seen. For example, a SampleRate of 30
  # will keep 1 out of every 30 traces.
  SampleRate: 1

  ## Dataset sampling rules ##
  # Specify dataset rules by creating an object for each dataset
  # Note: If your dataset name contains a space, you will have to escape the dataset name
  # using single quotes, such as "dataset 1":
  #
  # This example creates a sampling definition for a dataset called: test-dataset
  # test-dataset:
  #   Sampler: EMADynamicSampler
  #   GoalSampleRate: 5
  #   FieldList:
  #    - request.method
  #    - response.status_code

  # LiveReload - If disabled, triggers a rolling restart of the cluster whenever
  # the Rules configmap changes
  LiveReload: true


# Redis configuration
redis:
  # To install a simple single pod Redis deployment set this to true.
  # If false, you must specify a value for existingHost
  # For production, it is recommended to set this to false and provide
  # a highly available Redis configuration using redis.existingHost
  enabled: true

  # If redis.enabled is false this needs to be specified.
  # This needs to be the name:port of a Redis configuration
  # existingHost:

  # If redis.enabled is true, this the image that will be used to create
  # the Redis deployment
  image:
    repository: redis
    tag: 6.2.5
    pullPolicy: IfNotPresent

  # Node selector specific to installed Redis configuration. Requires redis.enabled to be true
  nodeSelector: { }

  # Tolerations specific to installed Redis configuration. Requires redis.enabled to be true
  tolerations: [ ]

  # Affinity specific to installed Redis configuration. Requires redis.enabled to be true
  affinity: { }


nodeSelector: { }

